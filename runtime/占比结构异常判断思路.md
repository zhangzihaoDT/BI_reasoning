éå¸¸å¥½ï¼Œè¿™ä¸ªæ¨¡æ¿**å·²ç»æ˜¯ä¸€ä¸ªæˆç†Ÿçš„ã€Œåˆ†æåˆ¤æ–­ â†’ è¡ŒåŠ¨ç¼–æ’ã€éª¨æ¶**äº†ã€‚
æˆ‘ä¸ä¼šæ¨ç¿»å®ƒï¼Œè€Œæ˜¯**åœ¨ä½ ç°æœ‰ç»“æ„ä¸Šåšå¢å¼º**ï¼ŒæŠŠä½ åˆšæ‰æå‡ºçš„ï¼š

> ã€ŒåŒºåˆ†æ¯”ä¾‹å¼‚å¸¸æ˜¯ç»“æ„å¼‚å¸¸ï¼Œè¿˜æ˜¯åˆ†æ¯å˜åŒ–å¯¼è‡´çš„å‡å¼‚å¸¸ã€

**æ­£å¼æ³¨å…¥åˆ°åˆ¤å®šå±‚ä¸ plan å±‚**ã€‚

ä¸‹é¢æˆ‘æŒ‰ **è®¾è®¡æ€æƒ³ â†’ æ–°å¢æŠ½è±¡ â†’ ä»£ç å¢å¼ºï¼ˆå¯ç›´æ¥ç”¨ï¼‰** ä¸‰æ­¥æ¥ã€‚

---

# ä¸€ã€ä½ ç°æœ‰æ¨¡æ¿çš„â€œéšå«å‡è®¾â€ï¼ˆå…ˆç‚¹ç ´ï¼‰

ä½ ç°åœ¨çš„ `classify_anomaly_from_stats` é»˜è®¤å‡è®¾ï¼š

- å½“å‰ metric æ˜¯ **å•ä¸€æ—¶é—´åºåˆ—**
- ç”¨ **z-score + CV** åˆ¤æ–­ï¼š
  - ç¨³å®šä½†åç¦» â‡’ ç»“æ„æ€§å¼‚å¸¸
  - æ³¢åŠ¨å¤§ â‡’ é«˜æ³¢åŠ¨å¼‚å¸¸

âš ï¸ ä½†å®ƒ**æ— æ³•åŒºåˆ†**ï¼š

> ã€Œè¿™æ˜¯ _æ¯”ä¾‹_ æŒ‡æ ‡å¼‚å¸¸ï¼Œè¿˜æ˜¯ _ç»å¯¹é‡_ æŒ‡æ ‡å¼‚å¸¸ï¼Ÿã€

ä¹Ÿå°±æ˜¯è¯´ï¼š

- `è®¢å•å æ¯” â†‘`
  æ˜¯ **ç»“æ„å˜åŒ–**ï¼Ÿ
  è¿˜æ˜¯ **æ€»è®¢å• â†“**ï¼Ÿ

ğŸ‘‰ è¿™æ˜¯ä¸€ä¸ª**ä¿¡æ¯ç¼ºå£**ï¼Œä¸æ˜¯ç®—æ³•é—®é¢˜ã€‚

---

# äºŒã€å¢å¼ºæ€è·¯ï¼šå¼•å…¥ã€Œæ¯”ä¾‹â€“è§„æ¨¡è§£è€¦åˆ¤å®šå±‚ã€

æˆ‘ä»¬å¼•å…¥ä¸€ä¸ª**ç¬¬äºŒå±‚åˆ¤å®š**ï¼š

> **Ratio Decomposition Checkï¼ˆæ¯”ä¾‹è§£è€¦æ£€æŸ¥ï¼‰**

### æ ¸å¿ƒåˆ¤æ–­å˜é‡

| ç¬¦å·                | å«ä¹‰       |
| ------------------- | ---------- |
| ( x_i )             | åˆ†ç»„ç»å¯¹å€¼ |
| ( X )               | æ€»é‡       |
| ( p_i = x_i / X )   | åˆ†ç»„å æ¯”   |
| ( \Delta \log x_i ) | åˆ†ç»„å˜åŒ–   |
| ( \Delta \log X )   | æ•´ä½“å˜åŒ–   |
| ( \Delta \log p_i ) | æ¯”ä¾‹å˜åŒ–   |

---

# ä¸‰ã€å¢å¼º 1ï¼šæ‰©å±• AnomalyFlagï¼ˆä¸ç ´åå…¼å®¹æ€§ï¼‰

```python
AnomalyFlag = Literal[
    "ç»“æ„æ€§å¼‚å¸¸",
    "æ¯”ä¾‹å‡å¼‚å¸¸",      # æ–°å¢
    "é«˜æ³¢åŠ¨å¼‚å¸¸",
    "æ­£å¸¸æ³¢åŠ¨",
]
```

---

# å››ã€å¢å¼º 2ï¼šæ–°å¢ã€Œæ¯”ä¾‹è§£è€¦åˆ¤å®šå‡½æ•°ã€

### ğŸ‘‰ è¿™æ˜¯ä½ åˆšæ‰é‚£æ®µåˆ†æé€»è¾‘çš„**æ­£å¼ä»£ç åŒ–**

```python
def classify_ratio_decomposition(
    delta_group: float,
    delta_total: float,
    delta_ratio: float,
    ratio_threshold: float = 0.2,
    scale_threshold: float = 0.2,
) -> Optional[AnomalyDecision]:
    """
    ç”¨äºåˆ¤æ–­ï¼šæ¯”ä¾‹å¼‚å¸¸æ˜¯å¦ä¸ºç»“æ„å¼‚å¸¸ï¼Œè¿˜æ˜¯åˆ†æ¯æ•ˆåº”
    è¾“å…¥ä¸º log-diff æˆ– pct change
    """

    if abs(delta_ratio) < ratio_threshold:
        return None  # æ¯”ä¾‹æœ¬èº«ä¸æ˜¾è‘—ï¼Œä¸è§¦å‘

    # åˆ†ç»„æœ¬èº«å˜åŒ–æ˜¾è‘—ï¼Œä¸”ä¸æ˜¯æ•´ä½“ä¸€èµ·å˜
    if abs(delta_group) >= scale_threshold and abs(delta_group - delta_total) >= scale_threshold:
        return {
            "flag": "ç»“æ„æ€§å¼‚å¸¸",
            "z": delta_ratio,
            "cv": abs(delta_group),
            "anomaly_detected": True,
        }

    # æ¯”ä¾‹å¼‚å¸¸ä¸»è¦ç”±æ•´ä½“å˜åŒ–é©±åŠ¨
    if abs(delta_total) >= scale_threshold and abs(delta_group) < scale_threshold:
        return {
            "flag": "æ¯”ä¾‹å‡å¼‚å¸¸",
            "z": delta_ratio,
            "cv": abs(delta_total),
            "anomaly_detected": False,
        }

    return None
```

ğŸ§  **è§£é‡Š**ï¼š

- è¿™ä¸€æ­¥ä¸æ˜¯æ›¿ä»£ z-score
- è€Œæ˜¯ï¼š
  ğŸ‘‰ **å½“ metric æ˜¯æ¯”ä¾‹ç±»æŒ‡æ ‡æ—¶ï¼Œè¿½åŠ ä¸€è½®â€œå› æœæ ¡éªŒâ€**

---

# äº”ã€å¢å¼º 3ï¼šå‡çº§ evaluate_breadth_scan_and_planï¼ˆå…³é”®ï¼‰

ä½ ç°åœ¨æ˜¯ï¼š

```text
breadth scan â†’ anomaly â†’ drilldown
```

å¢å¼ºåæ˜¯ï¼š

```text
breadth scan
  â†’ æ•°å€¼å¼‚å¸¸ï¼Ÿ
    â†’ è‹¥æ˜¯æ¯”ä¾‹æŒ‡æ ‡ â†’ æ¯”ä¾‹è§£è€¦æ ¡éªŒ
      â†’ çœŸç»“æ„å¼‚å¸¸ï¼Ÿor åˆ†æ¯æ•ˆåº”ï¼Ÿ
```

### âœ… å¢å¼ºç‰ˆæ ¸å¿ƒé€»è¾‘ï¼ˆåªè´´å…³é”®å·®å¼‚ï¼‰

```python
def evaluate_breadth_scan_and_plan(
    results: Dict[str, Any],
    metric: str,
    date_range: str,
    dimensions: List[str],
    core_metrics: List[str],
    cv_threshold: float = 0.1,
) -> Dict[str, Any]:

    anomaly_node = results.get("anomaly_check") or results.get("short_term_trend")
    if not anomaly_node:
        return {
            "decision": {
                "flag": "æ­£å¸¸æ³¢åŠ¨",
                "z": 0.0,
                "cv": 0.0,
                "anomaly_detected": False,
            },
            "next_steps": [],
        }

    # === ç¬¬ä¸€å±‚ï¼šç»Ÿè®¡å¼‚å¸¸ ===
    decision = classify_anomaly_from_stats(
        value=float(anomaly_node.get("value", 0.0)),
        mean=float(anomaly_node.get("mean", 0.0)),
        std=float(anomaly_node.get("std", 0.0)),
        cv_threshold=cv_threshold,
    )

    # === ç¬¬äºŒå±‚ï¼šæ¯”ä¾‹è§£è€¦åˆ¤å®šï¼ˆä»…å½“æ˜¯ ratio metricï¼‰===
    if anomaly_node.get("metric_type") == "ratio":
        ratio_decision = classify_ratio_decomposition(
            delta_group=float(anomaly_node.get("delta_group", 0.0)),
            delta_total=float(anomaly_node.get("delta_total", 0.0)),
            delta_ratio=float(anomaly_node.get("delta_ratio", 0.0)),
        )
        if ratio_decision:
            decision = ratio_decision

    next_steps = build_additive_ratio_drilldown_plan(
        decision=decision,
        metric=metric,
        date_range=date_range,
        dimensions=dimensions,
        core_metrics=core_metrics,
    )

    return {
        "decision": decision,
        "next_steps": next_steps,
    }
```

---

# å…­ã€å¢å¼º 4ï¼šè®© Drilldown Plan å˜â€œèªæ˜â€

ç°åœ¨çš„ plan æ˜¯**æ— æ¡ä»¶ä¸‹é’»**ï¼Œå¯ä»¥ç¨å¾®å‡çº§ï¼š

```python
if decision["flag"] == "æ¯”ä¾‹å‡å¼‚å¸¸":
    return [
        {
            "id": "total_volume_check",
            "tool": "trend",
            "parameters": {
                "metric": "total_volume",
                "date_range": date_range,
            },
            "reasoning": "æ¯”ä¾‹å¼‚å¸¸ç–‘ä¼¼ç”±æ•´ä½“è§„æ¨¡å˜åŒ–å¯¼è‡´ï¼Œä¼˜å…ˆç¡®è®¤åˆ†æ¯å˜åŒ–ã€‚",
        }
    ]
```

ğŸ‘‰ **è¿™ä¸€æ­¥éå¸¸é‡è¦**
å®ƒä¼šæ˜¾è‘—å‡å°‘ã€Œæ— æ„ä¹‰çš„ç»´åº¦ä¸‹é’»ã€ã€‚

---

# ä¸ƒã€ä½ è¿™ä¸ªå¢å¼ºï¼Œæ”¾åœ¨ Agent ä½“ç³»é‡Œçš„å®šä½

ä»ä½ æ•´ä¸ª BI reasoning æ¶æ„çœ‹ï¼Œè¿™ä¸€æ­¥æ˜¯ï¼š

> **å¼‚å¸¸è§£é‡Š Agentï¼ˆAnomaly Explainerï¼‰**

å®ƒçš„èŒè´£ä¸æ˜¯ï¼š

- ç®—å¾—å‡†

è€Œæ˜¯ï¼š

- **å‘Šè¯‰ç³»ç»Ÿï¼šå€¼ä¸å€¼å¾—ç»§ç»­åˆ†æ**

ä½ å·²ç»åœ¨åšçš„äº‹æƒ…ï¼Œæœ¬è´¨æ˜¯ï¼š

> ğŸ‘‰ æŠŠâ€œèµ„æ·±åˆ†æå¸ˆçš„ç›´è§‰â€å†™æˆä»£ç 

---
